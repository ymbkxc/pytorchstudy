{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.pytorch安装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ubuntu16.04+anaconda+pytorch+torchvision\n",
    "    1.安装anaconda bash Anaconda3-5.2.0-Linux-x86_64.sh\n",
    "    2.安装pytorch和torchvision conda install pytorch-cpu torchvision-cpu -c pytorch\n",
    "    官网平时速度慢，经常httperror 12点往后网速好\n",
    "    3.方便调试 查看源码 安装pycharm社区版"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.pytorch基本概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Tensor\n",
    "\n",
    "        Tensor是PyTorch中重要的数据结构，可认为是一个高维数组。它可以是一个数（标量）、一维数组（向量）、二维数组（矩阵）以及更高维的数组。Tensor和Numpy的ndarrays类似，但Tensor可以使用GPU进行加速。Tensor的使用和Numpy及Matlab的接口十分相似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### autograd: 自动微分\n",
    "\n",
    "深度学习的算法本质上是通过反向传播求导数，而PyTorch的**`autograd`**模块则实现了此功能。在Tensor上的所有操作，autograd都能为它们自动提供微分，避免了手动计算导数的复杂过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    图像相关层主要包括卷积层（Conv）、池化层（Pool）等，这些层在实际使用中可分为一维(1D)、二维(2D)、三维（3D），池化方式又分为平均池化（AvgPool）、最大值池化（MaxPool）、自适应池化（AdaptiveAvgPool）等。而卷积层除了常用的前向卷积之外，还有逆卷积（TransposeConv）。\n",
    "    除了卷积层和池化层，深度学习中还将常用到以下几个层：\n",
    "- Linear：全连接层。\n",
    "- BatchNorm：批规范化层，分为1D、2D和3D。除了标准的BatchNorm之外，还有在风格迁移中常用到的InstanceNorm层。\n",
    "- Dropout：dropout层，用来防止过拟合，同样分为1D、2D和3D。\n",
    "\n",
    "    PyTorch实现了常见的激活函数，其具体的接口信息可参见官方文档[^3]，这些激活函数可作为独立的layer使用。这里将介绍最常用的激活函数ReLU，其数学表达式为：\n",
    "$$ReLU(x)=max(0,x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 损失函数\n",
    "\n",
    "nn实现了神经网络中大多数的损失函数，例如nn.MSELoss用来计算均方误差，nn.CrossEntropyLoss用来计算交叉熵损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 优化器\n",
    "在反向传播计算完所有参数的梯度后，还需要使用优化方法来更新网络的权重和参数，例如随机梯度下降法(SGD)的更新策略如下：\n",
    "```\n",
    "weight = weight - learning_rate * gradient\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  数据加载与预处理\n",
    "\n",
    "在深度学习中数据加载及预处理是非常复杂繁琐的，但PyTorch提供了一些可极大简化和加快数据处理流程的工具。同时，对于常用的数据集，PyTorch也提供了封装好的接口供用户快速调用，这些数据集主要保存在torchvison中。\n",
    "\n",
    "`torchvision`实现了常用的图像数据加载功能，例如Imagenet、CIFAR10、MNIST等，以及常用的数据转换操作，这极大地方便了数据加载，并且代码具有可重用性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.通用代码实现流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度残差网络（ResNet）搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![residual](./residual.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import  nn\n",
    "import torch as t\n",
    "from torch.nn import  functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1, shortcut=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "                nn.Conv2d(inchannel,outchannel,3,stride, 1,bias=False),\n",
    "                nn.BatchNorm2d(outchannel),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(outchannel,outchannel,3,1,1,bias=False),\n",
    "                nn.BatchNorm2d(outchannel) )\n",
    "        self.right = shortcut\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        residual = x if self.right is None else self.right(x)\n",
    "        out += residual\n",
    "        return F.relu(out)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.pre = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, 7, 2, 3, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(3, 2, 1))\n",
    "        self.layer1 = self._make_layer( 64, 64, 3)\n",
    "        self.layer2 = self._make_layer( 64, 128, 4, stride=2)\n",
    "        self.layer3 = self._make_layer( 128, 256, 6, stride=2)\n",
    "        self.layer4 = self._make_layer( 256, 512, 3, stride=2)\n",
    "\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _make_layer(self,  inchannel, outchannel, block_num, stride=1):\n",
    "\n",
    "        shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel,outchannel,1,stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel))\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(inchannel, outchannel, stride, shortcut))\n",
    "        \n",
    "        for i in range(1, block_num):\n",
    "            layers.append(ResidualBlock(outchannel, outchannel))\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pre(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = F.avg_pool2d(x, 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet()\n",
    "input  = t.randn(1, 3, 224, 224)\n",
    "o = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
