{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch as t\n",
    "from torch.autograd import Variable\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy pytorch 实现梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x维度 x_shape: (1, 4)\n",
      "w1维度 w1_shape: (4, 4)\n",
      "隐层维度 h_shape: (1, 4)\n",
      "relu层维度 h_relu_shape: (1, 4)\n",
      "w2维度 w2_shape: (4, 2)\n",
      "预测值维度 y_pred_shape: (1, 2)\n",
      "loss: 0 35.69235444874203\n",
      "损失函数梯度 grad_y_pred: (1, 2)\n",
      "w2梯度 grad_w2_shape: (4, 2)\n",
      "h_relu梯度 grad_h_relu_shape： (1, 4)\n",
      "w1梯度 grad_w1_shape： (4, 4)\n"
     ]
    }
   ],
   "source": [
    "N, D_in, H, D_out = 1, 4, 4, 2\n",
    "\n",
    "\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(1):\n",
    "    \n",
    "    h = x.dot(w1)#.dot 矩阵积\n",
    "    print('x维度 x_shape:',x.shape)\n",
    "    print('w1维度 w1_shape:',w1.shape)\n",
    "    print('隐层维度 h_shape:',h.shape)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    print('relu层维度 h_relu_shape:',h_relu.shape)\n",
    "    print('w2维度 w2_shape:',w2.shape)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "    print('预测值维度 y_pred_shape:',y_pred.shape)\n",
    "\n",
    "    # 计算并显示loss（损失）\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print('loss:',t, loss)\n",
    "\n",
    "    # 反向传播，计算w1、w2对loss的梯度\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    print('损失函数梯度 grad_y_pred:',grad_y_pred.shape)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    print('w2梯度 grad_w2_shape:',grad_w2.shape)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    print('h_relu梯度 grad_h_relu_shape：',grad_h_relu.shape)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    print('w1梯度 grad_w1_shape：',grad_w1.shape)\n",
    "    # 更新权重\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch 自动求导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建Tensor时添加参数requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old w1[0]: tensor(0.7478, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.6368, grad_fn=<SelectBackward>)\n",
      "0 34380824.0\n",
      "new w1[0]: tensor(0.7420, requires_grad=True)\n",
      "new w2[0]: tensor(0.3704, requires_grad=True)\n",
      "w1.gred before clean  tensor(5781.1064)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7420, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.3704, grad_fn=<SelectBackward>)\n",
      "1 32981862.0\n",
      "new w1[0]: tensor(0.7398, requires_grad=True)\n",
      "new w2[0]: tensor(0.6776, requires_grad=True)\n",
      "w1.gred before clean  tensor(2189.9116)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7398, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.6776, grad_fn=<SelectBackward>)\n",
      "2 35856876.0\n",
      "new w1[0]: tensor(0.7354, requires_grad=True)\n",
      "new w2[0]: tensor(0.3325, requires_grad=True)\n",
      "w1.gred before clean  tensor(4444.4629)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7354, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.3325, grad_fn=<SelectBackward>)\n",
      "3 36037712.0\n",
      "new w1[0]: tensor(0.7337, requires_grad=True)\n",
      "new w2[0]: tensor(0.6642, requires_grad=True)\n",
      "w1.gred before clean  tensor(1670.3540)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7337, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.6642, grad_fn=<SelectBackward>)\n",
      "4 29272956.0\n",
      "new w1[0]: tensor(0.7304, requires_grad=True)\n",
      "new w2[0]: tensor(0.3863, requires_grad=True)\n",
      "w1.gred before clean  tensor(3329.1355)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7304, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.3863, grad_fn=<SelectBackward>)\n",
      "5 18438260.0\n",
      "new w1[0]: tensor(0.7293, requires_grad=True)\n",
      "new w2[0]: tensor(0.5734, requires_grad=True)\n",
      "w1.gred before clean  tensor(1005.6125)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7293, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.5734, grad_fn=<SelectBackward>)\n",
      "6 9405353.0\n",
      "new w1[0]: tensor(0.7267, requires_grad=True)\n",
      "new w2[0]: tensor(0.4482, requires_grad=True)\n",
      "w1.gred before clean  tensor(2622.7087)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7267, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4482, grad_fn=<SelectBackward>)\n",
      "7 4565348.0\n",
      "new w1[0]: tensor(0.7250, requires_grad=True)\n",
      "new w2[0]: tensor(0.5042, requires_grad=True)\n",
      "w1.gred before clean  tensor(1678.6710)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7250, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.5042, grad_fn=<SelectBackward>)\n",
      "8 2437218.0\n",
      "new w1[0]: tensor(0.7230, requires_grad=True)\n",
      "new w2[0]: tensor(0.4631, requires_grad=True)\n",
      "w1.gred before clean  tensor(2065.1143)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7230, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4631, grad_fn=<SelectBackward>)\n",
      "9 1536458.625\n",
      "new w1[0]: tensor(0.7213, requires_grad=True)\n",
      "new w2[0]: tensor(0.4727, requires_grad=True)\n",
      "w1.gred before clean  tensor(1675.2842)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7213, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4727, grad_fn=<SelectBackward>)\n",
      "10 1112039.375\n",
      "new w1[0]: tensor(0.7196, requires_grad=True)\n",
      "new w2[0]: tensor(0.4582, requires_grad=True)\n",
      "w1.gred before clean  tensor(1689.7153)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7196, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4582, grad_fn=<SelectBackward>)\n",
      "11 875257.5625\n",
      "new w1[0]: tensor(0.7181, requires_grad=True)\n",
      "new w2[0]: tensor(0.4564, requires_grad=True)\n",
      "w1.gred before clean  tensor(1504.7161)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7181, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4564, grad_fn=<SelectBackward>)\n",
      "12 719586.1875\n",
      "new w1[0]: tensor(0.7167, requires_grad=True)\n",
      "new w2[0]: tensor(0.4496, requires_grad=True)\n",
      "w1.gred before clean  tensor(1438.9725)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7167, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4496, grad_fn=<SelectBackward>)\n",
      "13 605113.75\n",
      "new w1[0]: tensor(0.7153, requires_grad=True)\n",
      "new w2[0]: tensor(0.4459, requires_grad=True)\n",
      "w1.gred before clean  tensor(1325.1675)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7153, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4459, grad_fn=<SelectBackward>)\n",
      "14 515354.75\n",
      "new w1[0]: tensor(0.7141, requires_grad=True)\n",
      "new w2[0]: tensor(0.4415, requires_grad=True)\n",
      "w1.gred before clean  tensor(1249.2329)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7141, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4415, grad_fn=<SelectBackward>)\n",
      "15 442569.46875\n",
      "new w1[0]: tensor(0.7129, requires_grad=True)\n",
      "new w2[0]: tensor(0.4380, requires_grad=True)\n",
      "w1.gred before clean  tensor(1167.2271)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7129, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4380, grad_fn=<SelectBackward>)\n",
      "16 382410.625\n",
      "new w1[0]: tensor(0.7118, requires_grad=True)\n",
      "new w2[0]: tensor(0.4348, requires_grad=True)\n",
      "w1.gred before clean  tensor(1098.8751)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7118, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4348, grad_fn=<SelectBackward>)\n",
      "17 332070.46875\n",
      "new w1[0]: tensor(0.7108, requires_grad=True)\n",
      "new w2[0]: tensor(0.4318, requires_grad=True)\n",
      "w1.gred before clean  tensor(1035.1593)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7108, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4318, grad_fn=<SelectBackward>)\n",
      "18 289626.65625\n",
      "new w1[0]: tensor(0.7098, requires_grad=True)\n",
      "new w2[0]: tensor(0.4292, requires_grad=True)\n",
      "w1.gred before clean  tensor(976.7900)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7098, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4292, grad_fn=<SelectBackward>)\n",
      "19 253581.640625\n",
      "new w1[0]: tensor(0.7089, requires_grad=True)\n",
      "new w2[0]: tensor(0.4268, requires_grad=True)\n",
      "w1.gred before clean  tensor(922.2484)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7089, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4268, grad_fn=<SelectBackward>)\n",
      "20 222793.21875\n",
      "new w1[0]: tensor(0.7080, requires_grad=True)\n",
      "new w2[0]: tensor(0.4247, requires_grad=True)\n",
      "w1.gred before clean  tensor(871.5180)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7080, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4247, grad_fn=<SelectBackward>)\n",
      "21 196373.859375\n",
      "new w1[0]: tensor(0.7072, requires_grad=True)\n",
      "new w2[0]: tensor(0.4227, requires_grad=True)\n",
      "w1.gred before clean  tensor(823.3022)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7072, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4227, grad_fn=<SelectBackward>)\n",
      "22 173597.046875\n",
      "new w1[0]: tensor(0.7064, requires_grad=True)\n",
      "new w2[0]: tensor(0.4209, requires_grad=True)\n",
      "w1.gred before clean  tensor(778.0088)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7064, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4209, grad_fn=<SelectBackward>)\n",
      "23 153882.71875\n",
      "new w1[0]: tensor(0.7057, requires_grad=True)\n",
      "new w2[0]: tensor(0.4193, requires_grad=True)\n",
      "w1.gred before clean  tensor(736.1109)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7057, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4193, grad_fn=<SelectBackward>)\n",
      "24 136743.84375\n",
      "new w1[0]: tensor(0.7050, requires_grad=True)\n",
      "new w2[0]: tensor(0.4179, requires_grad=True)\n",
      "w1.gred before clean  tensor(696.5787)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7050, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4179, grad_fn=<SelectBackward>)\n",
      "25 121797.96875\n",
      "new w1[0]: tensor(0.7043, requires_grad=True)\n",
      "new w2[0]: tensor(0.4165, requires_grad=True)\n",
      "w1.gred before clean  tensor(659.8162)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7043, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4165, grad_fn=<SelectBackward>)\n",
      "26 108728.6015625\n",
      "new w1[0]: tensor(0.7037, requires_grad=True)\n",
      "new w2[0]: tensor(0.4154, requires_grad=True)\n",
      "w1.gred before clean  tensor(624.9012)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7037, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4154, grad_fn=<SelectBackward>)\n",
      "27 97270.0078125\n",
      "new w1[0]: tensor(0.7031, requires_grad=True)\n",
      "new w2[0]: tensor(0.4143, requires_grad=True)\n",
      "w1.gred before clean  tensor(592.7463)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7031, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4143, grad_fn=<SelectBackward>)\n",
      "28 87224.4453125\n",
      "new w1[0]: tensor(0.7026, requires_grad=True)\n",
      "new w2[0]: tensor(0.4133, requires_grad=True)\n",
      "w1.gred before clean  tensor(562.0511)\n",
      "w1.gred after clean  tensor(0.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old w1[0]: tensor(0.7026, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4133, grad_fn=<SelectBackward>)\n",
      "29 78381.78125\n",
      "new w1[0]: tensor(0.7020, requires_grad=True)\n",
      "new w2[0]: tensor(0.4124, requires_grad=True)\n",
      "w1.gred before clean  tensor(532.2345)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7020, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4124, grad_fn=<SelectBackward>)\n",
      "30 70558.6328125\n",
      "new w1[0]: tensor(0.7015, requires_grad=True)\n",
      "new w2[0]: tensor(0.4116, requires_grad=True)\n",
      "w1.gred before clean  tensor(504.6916)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7015, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4116, grad_fn=<SelectBackward>)\n",
      "31 63623.09765625\n",
      "new w1[0]: tensor(0.7010, requires_grad=True)\n",
      "new w2[0]: tensor(0.4109, requires_grad=True)\n",
      "w1.gred before clean  tensor(478.6253)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7010, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4109, grad_fn=<SelectBackward>)\n",
      "32 57451.56640625\n",
      "new w1[0]: tensor(0.7006, requires_grad=True)\n",
      "new w2[0]: tensor(0.4102, requires_grad=True)\n",
      "w1.gred before clean  tensor(453.9408)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7006, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4102, grad_fn=<SelectBackward>)\n",
      "33 51959.078125\n",
      "new w1[0]: tensor(0.7002, requires_grad=True)\n",
      "new w2[0]: tensor(0.4096, requires_grad=True)\n",
      "w1.gred before clean  tensor(430.8996)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.7002, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4096, grad_fn=<SelectBackward>)\n",
      "34 47059.66796875\n",
      "new w1[0]: tensor(0.6997, requires_grad=True)\n",
      "new w2[0]: tensor(0.4090, requires_grad=True)\n",
      "w1.gred before clean  tensor(409.2514)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6997, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4090, grad_fn=<SelectBackward>)\n",
      "35 42685.42578125\n",
      "new w1[0]: tensor(0.6994, requires_grad=True)\n",
      "new w2[0]: tensor(0.4085, requires_grad=True)\n",
      "w1.gred before clean  tensor(388.4310)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6994, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4085, grad_fn=<SelectBackward>)\n",
      "36 38768.85546875\n",
      "new w1[0]: tensor(0.6990, requires_grad=True)\n",
      "new w2[0]: tensor(0.4081, requires_grad=True)\n",
      "w1.gred before clean  tensor(368.9664)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6990, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4081, grad_fn=<SelectBackward>)\n",
      "37 35258.9453125\n",
      "new w1[0]: tensor(0.6986, requires_grad=True)\n",
      "new w2[0]: tensor(0.4077, requires_grad=True)\n",
      "w1.gred before clean  tensor(350.5610)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6986, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4077, grad_fn=<SelectBackward>)\n",
      "38 32105.08984375\n",
      "new w1[0]: tensor(0.6983, requires_grad=True)\n",
      "new w2[0]: tensor(0.4073, requires_grad=True)\n",
      "w1.gred before clean  tensor(333.1086)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6983, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4073, grad_fn=<SelectBackward>)\n",
      "39 29267.59765625\n",
      "new w1[0]: tensor(0.6980, requires_grad=True)\n",
      "new w2[0]: tensor(0.4070, requires_grad=True)\n",
      "w1.gred before clean  tensor(316.5167)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6980, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4070, grad_fn=<SelectBackward>)\n",
      "40 26711.1796875\n",
      "new w1[0]: tensor(0.6977, requires_grad=True)\n",
      "new w2[0]: tensor(0.4067, requires_grad=True)\n",
      "w1.gred before clean  tensor(301.0719)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6977, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4067, grad_fn=<SelectBackward>)\n",
      "41 24404.3125\n",
      "new w1[0]: tensor(0.6974, requires_grad=True)\n",
      "new w2[0]: tensor(0.4064, requires_grad=True)\n",
      "w1.gred before clean  tensor(286.2227)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6974, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4064, grad_fn=<SelectBackward>)\n",
      "42 22321.18359375\n",
      "new w1[0]: tensor(0.6971, requires_grad=True)\n",
      "new w2[0]: tensor(0.4062, requires_grad=True)\n",
      "w1.gred before clean  tensor(272.2252)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6971, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4062, grad_fn=<SelectBackward>)\n",
      "43 20436.3828125\n",
      "new w1[0]: tensor(0.6969, requires_grad=True)\n",
      "new w2[0]: tensor(0.4060, requires_grad=True)\n",
      "w1.gred before clean  tensor(258.8465)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6969, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4060, grad_fn=<SelectBackward>)\n",
      "44 18729.42578125\n",
      "new w1[0]: tensor(0.6966, requires_grad=True)\n",
      "new w2[0]: tensor(0.4058, requires_grad=True)\n",
      "w1.gred before clean  tensor(246.2209)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6966, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4058, grad_fn=<SelectBackward>)\n",
      "45 17180.458984375\n",
      "new w1[0]: tensor(0.6964, requires_grad=True)\n",
      "new w2[0]: tensor(0.4057, requires_grad=True)\n",
      "w1.gred before clean  tensor(234.2542)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6964, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4057, grad_fn=<SelectBackward>)\n",
      "46 15776.32421875\n",
      "new w1[0]: tensor(0.6962, requires_grad=True)\n",
      "new w2[0]: tensor(0.4055, requires_grad=True)\n",
      "w1.gred before clean  tensor(222.8505)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6962, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4055, grad_fn=<SelectBackward>)\n",
      "47 14501.658203125\n",
      "new w1[0]: tensor(0.6960, requires_grad=True)\n",
      "new w2[0]: tensor(0.4054, requires_grad=True)\n",
      "w1.gred before clean  tensor(212.0546)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6960, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4054, grad_fn=<SelectBackward>)\n",
      "48 13341.4140625\n",
      "new w1[0]: tensor(0.6957, requires_grad=True)\n",
      "new w2[0]: tensor(0.4053, requires_grad=True)\n",
      "w1.gred before clean  tensor(201.7758)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6957, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4053, grad_fn=<SelectBackward>)\n",
      "49 12284.0078125\n",
      "new w1[0]: tensor(0.6956, requires_grad=True)\n",
      "new w2[0]: tensor(0.4053, requires_grad=True)\n",
      "w1.gred before clean  tensor(192.0195)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6956, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4053, grad_fn=<SelectBackward>)\n",
      "50 11319.46875\n",
      "new w1[0]: tensor(0.6954, requires_grad=True)\n",
      "new w2[0]: tensor(0.4052, requires_grad=True)\n",
      "w1.gred before clean  tensor(182.6867)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6954, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4052, grad_fn=<SelectBackward>)\n",
      "51 10439.3427734375\n",
      "new w1[0]: tensor(0.6952, requires_grad=True)\n",
      "new w2[0]: tensor(0.4052, requires_grad=True)\n",
      "w1.gred before clean  tensor(173.9441)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6952, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4052, grad_fn=<SelectBackward>)\n",
      "52 9635.0537109375\n",
      "new w1[0]: tensor(0.6950, requires_grad=True)\n",
      "new w2[0]: tensor(0.4051, requires_grad=True)\n",
      "w1.gred before clean  tensor(165.5194)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6950, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4051, grad_fn=<SelectBackward>)\n",
      "53 8899.296875\n",
      "new w1[0]: tensor(0.6949, requires_grad=True)\n",
      "new w2[0]: tensor(0.4051, requires_grad=True)\n",
      "w1.gred before clean  tensor(157.5770)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6949, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4051, grad_fn=<SelectBackward>)\n",
      "54 8225.3896484375\n",
      "new w1[0]: tensor(0.6947, requires_grad=True)\n",
      "new w2[0]: tensor(0.4051, requires_grad=True)\n",
      "w1.gred before clean  tensor(150.0200)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6947, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4051, grad_fn=<SelectBackward>)\n",
      "55 7608.74365234375\n",
      "new w1[0]: tensor(0.6946, requires_grad=True)\n",
      "new w2[0]: tensor(0.4051, requires_grad=True)\n",
      "w1.gred before clean  tensor(142.8025)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6946, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4051, grad_fn=<SelectBackward>)\n",
      "56 7043.83056640625\n",
      "new w1[0]: tensor(0.6944, requires_grad=True)\n",
      "new w2[0]: tensor(0.4051, requires_grad=True)\n",
      "w1.gred before clean  tensor(136.0032)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6944, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4051, grad_fn=<SelectBackward>)\n",
      "57 6525.2529296875\n",
      "new w1[0]: tensor(0.6943, requires_grad=True)\n",
      "new w2[0]: tensor(0.4052, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1.gred before clean  tensor(129.4931)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6943, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4052, grad_fn=<SelectBackward>)\n",
      "58 6048.72216796875\n",
      "new w1[0]: tensor(0.6942, requires_grad=True)\n",
      "new w2[0]: tensor(0.4052, requires_grad=True)\n",
      "w1.gred before clean  tensor(123.3812)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6942, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4052, grad_fn=<SelectBackward>)\n",
      "59 5610.90673828125\n",
      "new w1[0]: tensor(0.6941, requires_grad=True)\n",
      "new w2[0]: tensor(0.4053, requires_grad=True)\n",
      "w1.gred before clean  tensor(117.5195)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6941, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4053, grad_fn=<SelectBackward>)\n",
      "60 5208.11328125\n",
      "new w1[0]: tensor(0.6940, requires_grad=True)\n",
      "new w2[0]: tensor(0.4053, requires_grad=True)\n",
      "w1.gred before clean  tensor(111.9705)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6940, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4053, grad_fn=<SelectBackward>)\n",
      "61 4836.87548828125\n",
      "new w1[0]: tensor(0.6939, requires_grad=True)\n",
      "new w2[0]: tensor(0.4054, requires_grad=True)\n",
      "w1.gred before clean  tensor(106.6868)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6939, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4054, grad_fn=<SelectBackward>)\n",
      "62 4494.9677734375\n",
      "new w1[0]: tensor(0.6938, requires_grad=True)\n",
      "new w2[0]: tensor(0.4054, requires_grad=True)\n",
      "w1.gred before clean  tensor(101.6758)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6938, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4054, grad_fn=<SelectBackward>)\n",
      "63 4179.63427734375\n",
      "new w1[0]: tensor(0.6937, requires_grad=True)\n",
      "new w2[0]: tensor(0.4055, requires_grad=True)\n",
      "w1.gred before clean  tensor(96.9106)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6937, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4055, grad_fn=<SelectBackward>)\n",
      "64 3888.60986328125\n",
      "new w1[0]: tensor(0.6936, requires_grad=True)\n",
      "new w2[0]: tensor(0.4056, requires_grad=True)\n",
      "w1.gred before clean  tensor(92.3774)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6936, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4056, grad_fn=<SelectBackward>)\n",
      "65 3619.96044921875\n",
      "new w1[0]: tensor(0.6935, requires_grad=True)\n",
      "new w2[0]: tensor(0.4056, requires_grad=True)\n",
      "w1.gred before clean  tensor(88.0606)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6935, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4056, grad_fn=<SelectBackward>)\n",
      "66 3371.7568359375\n",
      "new w1[0]: tensor(0.6934, requires_grad=True)\n",
      "new w2[0]: tensor(0.4057, requires_grad=True)\n",
      "w1.gred before clean  tensor(83.9530)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6934, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4057, grad_fn=<SelectBackward>)\n",
      "67 3142.31005859375\n",
      "new w1[0]: tensor(0.6933, requires_grad=True)\n",
      "new w2[0]: tensor(0.4058, requires_grad=True)\n",
      "w1.gred before clean  tensor(80.0469)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6933, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4058, grad_fn=<SelectBackward>)\n",
      "68 2930.0439453125\n",
      "new w1[0]: tensor(0.6932, requires_grad=True)\n",
      "new w2[0]: tensor(0.4059, requires_grad=True)\n",
      "w1.gred before clean  tensor(76.3495)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6932, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4059, grad_fn=<SelectBackward>)\n",
      "69 2733.542236328125\n",
      "new w1[0]: tensor(0.6932, requires_grad=True)\n",
      "new w2[0]: tensor(0.4060, requires_grad=True)\n",
      "w1.gred before clean  tensor(72.8083)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6932, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4060, grad_fn=<SelectBackward>)\n",
      "70 2551.5498046875\n",
      "new w1[0]: tensor(0.6931, requires_grad=True)\n",
      "new w2[0]: tensor(0.4061, requires_grad=True)\n",
      "w1.gred before clean  tensor(69.4542)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6931, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4061, grad_fn=<SelectBackward>)\n",
      "71 2382.87744140625\n",
      "new w1[0]: tensor(0.6930, requires_grad=True)\n",
      "new w2[0]: tensor(0.4062, requires_grad=True)\n",
      "w1.gred before clean  tensor(66.2745)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6930, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4062, grad_fn=<SelectBackward>)\n",
      "72 2226.468505859375\n",
      "new w1[0]: tensor(0.6930, requires_grad=True)\n",
      "new w2[0]: tensor(0.4063, requires_grad=True)\n",
      "w1.gred before clean  tensor(63.2458)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6930, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4063, grad_fn=<SelectBackward>)\n",
      "73 2081.3486328125\n",
      "new w1[0]: tensor(0.6929, requires_grad=True)\n",
      "new w2[0]: tensor(0.4064, requires_grad=True)\n",
      "w1.gred before clean  tensor(60.3507)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6929, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4064, grad_fn=<SelectBackward>)\n",
      "74 1946.66943359375\n",
      "new w1[0]: tensor(0.6929, requires_grad=True)\n",
      "new w2[0]: tensor(0.4065, requires_grad=True)\n",
      "w1.gred before clean  tensor(57.6026)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6929, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4065, grad_fn=<SelectBackward>)\n",
      "75 1821.5098876953125\n",
      "new w1[0]: tensor(0.6928, requires_grad=True)\n",
      "new w2[0]: tensor(0.4066, requires_grad=True)\n",
      "w1.gred before clean  tensor(54.9705)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6928, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4066, grad_fn=<SelectBackward>)\n",
      "76 1705.111083984375\n",
      "new w1[0]: tensor(0.6927, requires_grad=True)\n",
      "new w2[0]: tensor(0.4067, requires_grad=True)\n",
      "w1.gred before clean  tensor(52.4637)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6927, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4067, grad_fn=<SelectBackward>)\n",
      "77 1596.885986328125\n",
      "new w1[0]: tensor(0.6927, requires_grad=True)\n",
      "new w2[0]: tensor(0.4068, requires_grad=True)\n",
      "w1.gred before clean  tensor(50.0716)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6927, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4068, grad_fn=<SelectBackward>)\n",
      "78 1496.1910400390625\n",
      "new w1[0]: tensor(0.6926, requires_grad=True)\n",
      "new w2[0]: tensor(0.4069, requires_grad=True)\n",
      "w1.gred before clean  tensor(47.7985)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6926, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4069, grad_fn=<SelectBackward>)\n",
      "79 1402.510009765625\n",
      "new w1[0]: tensor(0.6926, requires_grad=True)\n",
      "new w2[0]: tensor(0.4070, requires_grad=True)\n",
      "w1.gred before clean  tensor(45.6524)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6926, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4070, grad_fn=<SelectBackward>)\n",
      "80 1315.218017578125\n",
      "new w1[0]: tensor(0.6926, requires_grad=True)\n",
      "new w2[0]: tensor(0.4071, requires_grad=True)\n",
      "w1.gred before clean  tensor(43.6030)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6926, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4071, grad_fn=<SelectBackward>)\n",
      "81 1233.904296875\n",
      "new w1[0]: tensor(0.6925, requires_grad=True)\n",
      "new w2[0]: tensor(0.4073, requires_grad=True)\n",
      "w1.gred before clean  tensor(41.6276)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6925, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4073, grad_fn=<SelectBackward>)\n",
      "82 1158.09619140625\n",
      "new w1[0]: tensor(0.6925, requires_grad=True)\n",
      "new w2[0]: tensor(0.4074, requires_grad=True)\n",
      "w1.gred before clean  tensor(39.7468)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6925, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4074, grad_fn=<SelectBackward>)\n",
      "83 1087.3629150390625\n",
      "new w1[0]: tensor(0.6924, requires_grad=True)\n",
      "new w2[0]: tensor(0.4075, requires_grad=True)\n",
      "w1.gred before clean  tensor(37.9723)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6924, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4075, grad_fn=<SelectBackward>)\n",
      "84 1021.3936767578125\n",
      "new w1[0]: tensor(0.6924, requires_grad=True)\n",
      "new w2[0]: tensor(0.4076, requires_grad=True)\n",
      "w1.gred before clean  tensor(36.2883)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6924, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4076, grad_fn=<SelectBackward>)\n",
      "85 959.767578125\n",
      "new w1[0]: tensor(0.6924, requires_grad=True)\n",
      "new w2[0]: tensor(0.4077, requires_grad=True)\n",
      "w1.gred before clean  tensor(34.6684)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6924, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4077, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 902.20947265625\n",
      "new w1[0]: tensor(0.6923, requires_grad=True)\n",
      "new w2[0]: tensor(0.4078, requires_grad=True)\n",
      "w1.gred before clean  tensor(33.1365)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6923, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4078, grad_fn=<SelectBackward>)\n",
      "87 848.4454345703125\n",
      "new w1[0]: tensor(0.6923, requires_grad=True)\n",
      "new w2[0]: tensor(0.4079, requires_grad=True)\n",
      "w1.gred before clean  tensor(31.6727)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6923, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4079, grad_fn=<SelectBackward>)\n",
      "88 798.177734375\n",
      "new w1[0]: tensor(0.6923, requires_grad=True)\n",
      "new w2[0]: tensor(0.4080, requires_grad=True)\n",
      "w1.gred before clean  tensor(30.2763)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6923, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4080, grad_fn=<SelectBackward>)\n",
      "89 751.14111328125\n",
      "new w1[0]: tensor(0.6922, requires_grad=True)\n",
      "new w2[0]: tensor(0.4081, requires_grad=True)\n",
      "w1.gred before clean  tensor(28.9415)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6922, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4081, grad_fn=<SelectBackward>)\n",
      "90 707.1246948242188\n",
      "new w1[0]: tensor(0.6922, requires_grad=True)\n",
      "new w2[0]: tensor(0.4082, requires_grad=True)\n",
      "w1.gred before clean  tensor(27.6830)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6922, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4082, grad_fn=<SelectBackward>)\n",
      "91 665.9365234375\n",
      "new w1[0]: tensor(0.6922, requires_grad=True)\n",
      "new w2[0]: tensor(0.4084, requires_grad=True)\n",
      "w1.gred before clean  tensor(26.4729)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6922, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4084, grad_fn=<SelectBackward>)\n",
      "92 627.3372802734375\n",
      "new w1[0]: tensor(0.6922, requires_grad=True)\n",
      "new w2[0]: tensor(0.4085, requires_grad=True)\n",
      "w1.gred before clean  tensor(25.3241)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6922, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4085, grad_fn=<SelectBackward>)\n",
      "93 591.19677734375\n",
      "new w1[0]: tensor(0.6921, requires_grad=True)\n",
      "new w2[0]: tensor(0.4086, requires_grad=True)\n",
      "w1.gred before clean  tensor(24.2204)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6921, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4086, grad_fn=<SelectBackward>)\n",
      "94 557.32080078125\n",
      "new w1[0]: tensor(0.6921, requires_grad=True)\n",
      "new w2[0]: tensor(0.4087, requires_grad=True)\n",
      "w1.gred before clean  tensor(23.1693)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6921, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4087, grad_fn=<SelectBackward>)\n",
      "95 525.545166015625\n",
      "new w1[0]: tensor(0.6921, requires_grad=True)\n",
      "new w2[0]: tensor(0.4088, requires_grad=True)\n",
      "w1.gred before clean  tensor(22.1685)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6921, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4088, grad_fn=<SelectBackward>)\n",
      "96 495.72882080078125\n",
      "new w1[0]: tensor(0.6921, requires_grad=True)\n",
      "new w2[0]: tensor(0.4089, requires_grad=True)\n",
      "w1.gred before clean  tensor(21.2102)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6921, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4089, grad_fn=<SelectBackward>)\n",
      "97 467.75946044921875\n",
      "new w1[0]: tensor(0.6921, requires_grad=True)\n",
      "new w2[0]: tensor(0.4090, requires_grad=True)\n",
      "w1.gred before clean  tensor(20.3014)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6921, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4090, grad_fn=<SelectBackward>)\n",
      "98 441.49786376953125\n",
      "new w1[0]: tensor(0.6920, requires_grad=True)\n",
      "new w2[0]: tensor(0.4091, requires_grad=True)\n",
      "w1.gred before clean  tensor(19.4318)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6920, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4091, grad_fn=<SelectBackward>)\n",
      "99 416.8363952636719\n",
      "new w1[0]: tensor(0.6920, requires_grad=True)\n",
      "new w2[0]: tensor(0.4092, requires_grad=True)\n",
      "w1.gred before clean  tensor(18.5976)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6920, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4092, grad_fn=<SelectBackward>)\n",
      "100 393.6690979003906\n",
      "new w1[0]: tensor(0.6920, requires_grad=True)\n",
      "new w2[0]: tensor(0.4093, requires_grad=True)\n",
      "w1.gred before clean  tensor(17.8011)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6920, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4093, grad_fn=<SelectBackward>)\n",
      "101 371.8940734863281\n",
      "new w1[0]: tensor(0.6920, requires_grad=True)\n",
      "new w2[0]: tensor(0.4094, requires_grad=True)\n",
      "w1.gred before clean  tensor(17.0452)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6920, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4094, grad_fn=<SelectBackward>)\n",
      "102 351.4200744628906\n",
      "new w1[0]: tensor(0.6920, requires_grad=True)\n",
      "new w2[0]: tensor(0.4095, requires_grad=True)\n",
      "w1.gred before clean  tensor(16.3309)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6920, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4095, grad_fn=<SelectBackward>)\n",
      "103 332.16070556640625\n",
      "new w1[0]: tensor(0.6919, requires_grad=True)\n",
      "new w2[0]: tensor(0.4096, requires_grad=True)\n",
      "w1.gred before clean  tensor(15.6316)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6919, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4096, grad_fn=<SelectBackward>)\n",
      "104 314.04364013671875\n",
      "new w1[0]: tensor(0.6919, requires_grad=True)\n",
      "new w2[0]: tensor(0.4097, requires_grad=True)\n",
      "w1.gred before clean  tensor(14.9731)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6919, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4097, grad_fn=<SelectBackward>)\n",
      "105 296.9907531738281\n",
      "new w1[0]: tensor(0.6919, requires_grad=True)\n",
      "new w2[0]: tensor(0.4098, requires_grad=True)\n",
      "w1.gred before clean  tensor(14.3455)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6919, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4098, grad_fn=<SelectBackward>)\n",
      "106 280.93511962890625\n",
      "new w1[0]: tensor(0.6919, requires_grad=True)\n",
      "new w2[0]: tensor(0.4099, requires_grad=True)\n",
      "w1.gred before clean  tensor(13.7456)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6919, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4099, grad_fn=<SelectBackward>)\n",
      "107 265.813232421875\n",
      "new w1[0]: tensor(0.6919, requires_grad=True)\n",
      "new w2[0]: tensor(0.4100, requires_grad=True)\n",
      "w1.gred before clean  tensor(13.1687)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6919, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4100, grad_fn=<SelectBackward>)\n",
      "108 251.5693817138672\n",
      "new w1[0]: tensor(0.6919, requires_grad=True)\n",
      "new w2[0]: tensor(0.4100, requires_grad=True)\n",
      "w1.gred before clean  tensor(12.6176)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6919, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4100, grad_fn=<SelectBackward>)\n",
      "109 238.1433868408203\n",
      "new w1[0]: tensor(0.6919, requires_grad=True)\n",
      "new w2[0]: tensor(0.4101, requires_grad=True)\n",
      "w1.gred before clean  tensor(12.0888)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6919, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4101, grad_fn=<SelectBackward>)\n",
      "110 225.4883270263672\n",
      "new w1[0]: tensor(0.6919, requires_grad=True)\n",
      "new w2[0]: tensor(0.4102, requires_grad=True)\n",
      "w1.gred before clean  tensor(11.5852)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6919, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4102, grad_fn=<SelectBackward>)\n",
      "111 213.55575561523438\n",
      "new w1[0]: tensor(0.6918, requires_grad=True)\n",
      "new w2[0]: tensor(0.4103, requires_grad=True)\n",
      "w1.gred before clean  tensor(11.1055)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6918, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4103, grad_fn=<SelectBackward>)\n",
      "112 202.2989501953125\n",
      "new w1[0]: tensor(0.6918, requires_grad=True)\n",
      "new w2[0]: tensor(0.4104, requires_grad=True)\n",
      "w1.gred before clean  tensor(10.6413)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6918, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4104, grad_fn=<SelectBackward>)\n",
      "113 191.6746368408203\n",
      "new w1[0]: tensor(0.6918, requires_grad=True)\n",
      "new w2[0]: tensor(0.4105, requires_grad=True)\n",
      "w1.gred before clean  tensor(10.2022)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6918, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4105, grad_fn=<SelectBackward>)\n",
      "114 181.64991760253906\n",
      "new w1[0]: tensor(0.6918, requires_grad=True)\n",
      "new w2[0]: tensor(0.4106, requires_grad=True)\n",
      "w1.gred before clean  tensor(9.7794)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6918, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4106, grad_fn=<SelectBackward>)\n",
      "115 172.18374633789062\n",
      "new w1[0]: tensor(0.6918, requires_grad=True)\n",
      "new w2[0]: tensor(0.4106, requires_grad=True)\n",
      "w1.gred before clean  tensor(9.3786)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6918, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4106, grad_fn=<SelectBackward>)\n",
      "116 163.2440643310547\n",
      "new w1[0]: tensor(0.6918, requires_grad=True)\n",
      "new w2[0]: tensor(0.4107, requires_grad=True)\n",
      "w1.gred before clean  tensor(8.9923)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6918, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4107, grad_fn=<SelectBackward>)\n",
      "117 154.80064392089844\n",
      "new w1[0]: tensor(0.6918, requires_grad=True)\n",
      "new w2[0]: tensor(0.4108, requires_grad=True)\n",
      "w1.gred before clean  tensor(8.6284)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6918, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4108, grad_fn=<SelectBackward>)\n",
      "118 146.8227996826172\n",
      "new w1[0]: tensor(0.6918, requires_grad=True)\n",
      "new w2[0]: tensor(0.4109, requires_grad=True)\n",
      "w1.gred before clean  tensor(8.2749)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6918, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4109, grad_fn=<SelectBackward>)\n",
      "119 139.2830047607422\n",
      "new w1[0]: tensor(0.6918, requires_grad=True)\n",
      "new w2[0]: tensor(0.4110, requires_grad=True)\n",
      "w1.gred before clean  tensor(7.9341)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6918, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4110, grad_fn=<SelectBackward>)\n",
      "120 132.15521240234375\n",
      "new w1[0]: tensor(0.6918, requires_grad=True)\n",
      "new w2[0]: tensor(0.4110, requires_grad=True)\n",
      "w1.gred before clean  tensor(7.6117)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6918, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4110, grad_fn=<SelectBackward>)\n",
      "121 125.41349792480469\n",
      "new w1[0]: tensor(0.6918, requires_grad=True)\n",
      "new w2[0]: tensor(0.4111, requires_grad=True)\n",
      "w1.gred before clean  tensor(7.2995)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6918, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4111, grad_fn=<SelectBackward>)\n",
      "122 119.04042053222656\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4112, requires_grad=True)\n",
      "w1.gred before clean  tensor(6.9974)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4112, grad_fn=<SelectBackward>)\n",
      "123 113.0090560913086\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4112, requires_grad=True)\n",
      "w1.gred before clean  tensor(6.7146)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4112, grad_fn=<SelectBackward>)\n",
      "124 107.30113220214844\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4113, requires_grad=True)\n",
      "w1.gred before clean  tensor(6.4433)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4113, grad_fn=<SelectBackward>)\n",
      "125 101.89776611328125\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4114, requires_grad=True)\n",
      "w1.gred before clean  tensor(6.1826)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4114, grad_fn=<SelectBackward>)\n",
      "126 96.78356170654297\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4115, requires_grad=True)\n",
      "w1.gred before clean  tensor(5.9318)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4115, grad_fn=<SelectBackward>)\n",
      "127 91.93989562988281\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4115, requires_grad=True)\n",
      "w1.gred before clean  tensor(5.6939)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4115, grad_fn=<SelectBackward>)\n",
      "128 87.35307312011719\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4116, requires_grad=True)\n",
      "w1.gred before clean  tensor(5.4630)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4116, grad_fn=<SelectBackward>)\n",
      "129 83.00814819335938\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4116, requires_grad=True)\n",
      "w1.gred before clean  tensor(5.2462)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4116, grad_fn=<SelectBackward>)\n",
      "130 78.8902816772461\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4117, requires_grad=True)\n",
      "w1.gred before clean  tensor(5.0378)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4117, grad_fn=<SelectBackward>)\n",
      "131 74.9869155883789\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4118, requires_grad=True)\n",
      "w1.gred before clean  tensor(4.8299)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4118, grad_fn=<SelectBackward>)\n",
      "132 71.28663635253906\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4118, requires_grad=True)\n",
      "w1.gred before clean  tensor(4.6348)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4118, grad_fn=<SelectBackward>)\n",
      "133 67.7798843383789\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4119, requires_grad=True)\n",
      "w1.gred before clean  tensor(4.4524)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4119, grad_fn=<SelectBackward>)\n",
      "134 64.45348358154297\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4120, requires_grad=True)\n",
      "w1.gred before clean  tensor(4.2744)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4120, grad_fn=<SelectBackward>)\n",
      "135 61.29912567138672\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4120, requires_grad=True)\n",
      "w1.gred before clean  tensor(4.1053)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4120, grad_fn=<SelectBackward>)\n",
      "136 58.30527114868164\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4121, requires_grad=True)\n",
      "w1.gred before clean  tensor(3.9393)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4121, grad_fn=<SelectBackward>)\n",
      "137 55.465797424316406\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4121, requires_grad=True)\n",
      "w1.gred before clean  tensor(3.7797)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4121, grad_fn=<SelectBackward>)\n",
      "138 52.772274017333984\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4122, requires_grad=True)\n",
      "w1.gred before clean  tensor(3.6328)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4122, grad_fn=<SelectBackward>)\n",
      "139 50.214195251464844\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4122, requires_grad=True)\n",
      "w1.gred before clean  tensor(3.4843)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4122, grad_fn=<SelectBackward>)\n",
      "140 47.785400390625\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4123, requires_grad=True)\n",
      "w1.gred before clean  tensor(3.3471)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4123, grad_fn=<SelectBackward>)\n",
      "141 45.4801139831543\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4123, requires_grad=True)\n",
      "w1.gred before clean  tensor(3.2101)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4123, grad_fn=<SelectBackward>)\n",
      "142 43.290740966796875\n",
      "new w1[0]: tensor(0.6917, requires_grad=True)\n",
      "new w2[0]: tensor(0.4124, requires_grad=True)\n",
      "w1.gred before clean  tensor(3.0858)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6917, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4124, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 41.211181640625\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4124, requires_grad=True)\n",
      "w1.gred before clean  tensor(2.9633)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4124, grad_fn=<SelectBackward>)\n",
      "144 39.236549377441406\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4125, requires_grad=True)\n",
      "w1.gred before clean  tensor(2.8420)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4125, grad_fn=<SelectBackward>)\n",
      "145 37.35990905761719\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4125, requires_grad=True)\n",
      "w1.gred before clean  tensor(2.7317)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4125, grad_fn=<SelectBackward>)\n",
      "146 35.57772445678711\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4126, requires_grad=True)\n",
      "w1.gred before clean  tensor(2.6233)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4126, grad_fn=<SelectBackward>)\n",
      "147 33.883522033691406\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4126, requires_grad=True)\n",
      "w1.gred before clean  tensor(2.5164)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4126, grad_fn=<SelectBackward>)\n",
      "148 32.273162841796875\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4127, requires_grad=True)\n",
      "w1.gred before clean  tensor(2.4166)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4127, grad_fn=<SelectBackward>)\n",
      "149 30.742935180664062\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4127, requires_grad=True)\n",
      "w1.gred before clean  tensor(2.3208)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4127, grad_fn=<SelectBackward>)\n",
      "150 29.28708839416504\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4128, requires_grad=True)\n",
      "w1.gred before clean  tensor(2.2264)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4128, grad_fn=<SelectBackward>)\n",
      "151 27.903846740722656\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4128, requires_grad=True)\n",
      "w1.gred before clean  tensor(2.1371)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4128, grad_fn=<SelectBackward>)\n",
      "152 26.588346481323242\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4128, requires_grad=True)\n",
      "w1.gred before clean  tensor(2.0526)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4128, grad_fn=<SelectBackward>)\n",
      "153 25.337154388427734\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4129, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.9716)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4129, grad_fn=<SelectBackward>)\n",
      "154 24.146387100219727\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4129, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.8882)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4129, grad_fn=<SelectBackward>)\n",
      "155 23.013973236083984\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4130, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.8109)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4130, grad_fn=<SelectBackward>)\n",
      "156 21.936838150024414\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4130, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.7408)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4130, grad_fn=<SelectBackward>)\n",
      "157 20.91106414794922\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4130, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.6721)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4130, grad_fn=<SelectBackward>)\n",
      "158 19.934972763061523\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4131, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.6026)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4131, grad_fn=<SelectBackward>)\n",
      "159 19.006698608398438\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4131, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.5421)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4131, grad_fn=<SelectBackward>)\n",
      "160 18.12233543395996\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4131, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.4828)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4131, grad_fn=<SelectBackward>)\n",
      "161 17.280559539794922\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4132, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.4200)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4132, grad_fn=<SelectBackward>)\n",
      "162 16.47978973388672\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4132, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.3666)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4132, grad_fn=<SelectBackward>)\n",
      "163 15.716018676757812\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4132, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.3076)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4132, grad_fn=<SelectBackward>)\n",
      "164 14.989510536193848\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4133, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.2546)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4133, grad_fn=<SelectBackward>)\n",
      "165 14.29730224609375\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4133, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.2043)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4133, grad_fn=<SelectBackward>)\n",
      "166 13.638086318969727\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4133, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.1549)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4133, grad_fn=<SelectBackward>)\n",
      "167 13.010685920715332\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4134, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.1058)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4134, grad_fn=<SelectBackward>)\n",
      "168 12.412553787231445\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4134, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.0634)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4134, grad_fn=<SelectBackward>)\n",
      "169 11.842439651489258\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4134, requires_grad=True)\n",
      "w1.gred before clean  tensor(1.0183)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4134, grad_fn=<SelectBackward>)\n",
      "170 11.299721717834473\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4135, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.9773)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4135, grad_fn=<SelectBackward>)\n",
      "171 10.7823486328125\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4135, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1.gred before clean  tensor(0.9356)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4135, grad_fn=<SelectBackward>)\n",
      "172 10.289016723632812\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4135, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.8980)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4135, grad_fn=<SelectBackward>)\n",
      "173 9.819246292114258\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4135, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.8584)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4135, grad_fn=<SelectBackward>)\n",
      "174 9.371456146240234\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4136, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.8239)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4136, grad_fn=<SelectBackward>)\n",
      "175 8.944395065307617\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4136, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.7913)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4136, grad_fn=<SelectBackward>)\n",
      "176 8.537212371826172\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4136, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.7545)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4136, grad_fn=<SelectBackward>)\n",
      "177 8.149496078491211\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4136, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.7270)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4136, grad_fn=<SelectBackward>)\n",
      "178 7.779472827911377\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4137, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.6957)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4137, grad_fn=<SelectBackward>)\n",
      "179 7.427077293395996\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4137, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.6664)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4137, grad_fn=<SelectBackward>)\n",
      "180 7.090414047241211\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4137, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.6339)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4137, grad_fn=<SelectBackward>)\n",
      "181 6.769811153411865\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4137, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.6097)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4137, grad_fn=<SelectBackward>)\n",
      "182 6.463996410369873\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4137, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.5864)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4137, grad_fn=<SelectBackward>)\n",
      "183 6.171892166137695\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4138, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.5584)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4138, grad_fn=<SelectBackward>)\n",
      "184 5.893568515777588\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4138, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.5309)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4138, grad_fn=<SelectBackward>)\n",
      "185 5.628329277038574\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4138, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.5093)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4138, grad_fn=<SelectBackward>)\n",
      "186 5.374953746795654\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4138, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.4894)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4138, grad_fn=<SelectBackward>)\n",
      "187 5.133024215698242\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4139, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.4693)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4139, grad_fn=<SelectBackward>)\n",
      "188 4.902628421783447\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4139, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.4456)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4139, grad_fn=<SelectBackward>)\n",
      "189 4.682909965515137\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4139, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.4265)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4139, grad_fn=<SelectBackward>)\n",
      "190 4.473028182983398\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4139, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.4076)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4139, grad_fn=<SelectBackward>)\n",
      "191 4.2724504470825195\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4139, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.3914)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4139, grad_fn=<SelectBackward>)\n",
      "192 4.081578254699707\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4139, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.3723)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4139, grad_fn=<SelectBackward>)\n",
      "193 3.899176597595215\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4140, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.3517)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4140, grad_fn=<SelectBackward>)\n",
      "194 3.7249393463134766\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4140, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.3375)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4140, grad_fn=<SelectBackward>)\n",
      "195 3.5588603019714355\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4140, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.3220)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4140, grad_fn=<SelectBackward>)\n",
      "196 3.400205135345459\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4140, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.3114)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4140, grad_fn=<SelectBackward>)\n",
      "197 3.2488625049591064\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4140, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.2962)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4140, grad_fn=<SelectBackward>)\n",
      "198 3.1042513847351074\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4140, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.2783)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4140, grad_fn=<SelectBackward>)\n",
      "199 2.966158866882324\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4141, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.2660)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old w2[0]: tensor(0.4141, grad_fn=<SelectBackward>)\n",
      "200 2.834585428237915\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4141, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.2530)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4141, grad_fn=<SelectBackward>)\n",
      "201 2.7088940143585205\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4141, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.2396)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4141, grad_fn=<SelectBackward>)\n",
      "202 2.588787317276001\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4141, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.2281)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4141, grad_fn=<SelectBackward>)\n",
      "203 2.474078416824341\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4141, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.2178)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4141, grad_fn=<SelectBackward>)\n",
      "204 2.364593744277954\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4141, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.2068)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4141, grad_fn=<SelectBackward>)\n",
      "205 2.259921073913574\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4141, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.1969)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4141, grad_fn=<SelectBackward>)\n",
      "206 2.1599574089050293\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4142, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.1824)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4142, grad_fn=<SelectBackward>)\n",
      "207 2.064697027206421\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4142, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.1744)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4142, grad_fn=<SelectBackward>)\n",
      "208 1.9737004041671753\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4142, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.1659)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4142, grad_fn=<SelectBackward>)\n",
      "209 1.8866891860961914\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4142, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.1565)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4142, grad_fn=<SelectBackward>)\n",
      "210 1.8035292625427246\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4142, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.1501)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4142, grad_fn=<SelectBackward>)\n",
      "211 1.724151611328125\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4142, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.1376)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4142, grad_fn=<SelectBackward>)\n",
      "212 1.6482725143432617\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4142, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.1318)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4142, grad_fn=<SelectBackward>)\n",
      "213 1.575829029083252\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4142, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.1238)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4142, grad_fn=<SelectBackward>)\n",
      "214 1.5066285133361816\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4142, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.1180)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4142, grad_fn=<SelectBackward>)\n",
      "215 1.4404230117797852\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4143, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.1080)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4143, grad_fn=<SelectBackward>)\n",
      "216 1.3771660327911377\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4143, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.1046)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4143, grad_fn=<SelectBackward>)\n",
      "217 1.3168846368789673\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4143, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0992)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4143, grad_fn=<SelectBackward>)\n",
      "218 1.259382724761963\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4143, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0910)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4143, grad_fn=<SelectBackward>)\n",
      "219 1.2041624784469604\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4143, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0855)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4143, grad_fn=<SelectBackward>)\n",
      "220 1.1515228748321533\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4143, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0826)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4143, grad_fn=<SelectBackward>)\n",
      "221 1.1012005805969238\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4143, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0735)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4143, grad_fn=<SelectBackward>)\n",
      "222 1.05300772190094\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4143, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0710)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4143, grad_fn=<SelectBackward>)\n",
      "223 1.0070407390594482\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4143, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0675)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4143, grad_fn=<SelectBackward>)\n",
      "224 0.9631122350692749\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4143, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0596)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4143, grad_fn=<SelectBackward>)\n",
      "225 0.9212123155593872\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4143, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0563)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4143, grad_fn=<SelectBackward>)\n",
      "226 0.8810674548149109\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4144, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0504)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4144, grad_fn=<SelectBackward>)\n",
      "227 0.8426864743232727\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4144, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0453)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4144, grad_fn=<SelectBackward>)\n",
      "228 0.8061428666114807\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new w2[0]: tensor(0.4144, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0438)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4144, grad_fn=<SelectBackward>)\n",
      "229 0.771088719367981\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4144, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0393)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4144, grad_fn=<SelectBackward>)\n",
      "230 0.737546443939209\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4144, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0321)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4144, grad_fn=<SelectBackward>)\n",
      "231 0.7054869532585144\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4144, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0310)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4144, grad_fn=<SelectBackward>)\n",
      "232 0.6749445796012878\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4144, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0286)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4144, grad_fn=<SelectBackward>)\n",
      "233 0.6457144618034363\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4144, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0231)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4144, grad_fn=<SelectBackward>)\n",
      "234 0.6177475452423096\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4144, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0223)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4144, grad_fn=<SelectBackward>)\n",
      "235 0.5910192131996155\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4144, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0218)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4144, grad_fn=<SelectBackward>)\n",
      "236 0.5654067993164062\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4144, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0169)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4144, grad_fn=<SelectBackward>)\n",
      "237 0.5410179495811462\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4144, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0135)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4144, grad_fn=<SelectBackward>)\n",
      "238 0.5176079273223877\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4144, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0114)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4144, grad_fn=<SelectBackward>)\n",
      "239 0.4952383041381836\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4144, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0101)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4144, grad_fn=<SelectBackward>)\n",
      "240 0.4738418757915497\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0092)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "241 0.4534222185611725\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(0.0026)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "242 0.4338131248950958\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0004)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "243 0.41509947180747986\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0015)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "244 0.39726483821868896\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0051)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "245 0.38014623522758484\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0062)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "246 0.3638044595718384\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0057)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "247 0.3481909930706024\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0065)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "248 0.3332010507583618\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0056)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "249 0.31895774602890015\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0082)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "250 0.30523180961608887\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0120)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "251 0.29217493534088135\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0124)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "252 0.2796536982059479\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0119)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "253 0.26765161752700806\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0159)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "254 0.2561710476875305\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0168)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "255 0.2452259361743927\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0137)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "256 0.2347092628479004\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0165)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "257 0.22466257214546204\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0191)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "258 0.21510513126850128\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0183)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "259 0.20595873892307281\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0181)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "260 0.19716860353946686\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0191)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "261 0.1887650489807129\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4145, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0207)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4145, grad_fn=<SelectBackward>)\n",
      "262 0.18071943521499634\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0201)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "263 0.17304599285125732\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0231)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "264 0.16562899947166443\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0240)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "265 0.15859784185886383\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0282)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "266 0.1518411934375763\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0253)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "267 0.14537560939788818\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0244)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "268 0.13920855522155762\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0260)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "269 0.13327328860759735\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0253)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "270 0.12763164937496185\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0282)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "271 0.1222386285662651\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0300)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "272 0.1170300841331482\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0277)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "273 0.1120719462633133\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0286)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "274 0.10732978582382202\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0318)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "275 0.1027950569987297\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0290)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "276 0.09841426461935043\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0295)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "277 0.0942932516336441\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0283)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "278 0.09029904007911682\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0279)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "279 0.08648236840963364\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0285)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "280 0.08286551386117935\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0298)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "281 0.07937668263912201\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0278)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "282 0.0760141909122467\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0301)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "283 0.0728188157081604\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0301)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "284 0.06975807249546051\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0295)\n",
      "w1.gred after clean  tensor(0.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "285 0.0668121948838234\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0283)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "286 0.06400805711746216\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0318)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "287 0.06132877618074417\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0314)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "288 0.058769747614860535\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0298)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "289 0.05628994107246399\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0289)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "290 0.053937435150146484\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0273)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "291 0.05166420713067055\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0284)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "292 0.049511004239320755\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0277)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "293 0.0474245548248291\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0306)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "294 0.0454539954662323\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0293)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "295 0.043545905500650406\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0288)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "296 0.04173413664102554\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0289)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "297 0.03998149186372757\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0292)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "298 0.038308948278427124\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0268)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "299 0.03672106936573982\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0268)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "300 0.03520971164107323\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0259)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "301 0.03374077379703522\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0261)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "302 0.032331518828868866\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0256)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "303 0.031001798808574677\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0247)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "304 0.029712801799178123\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0259)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "305 0.028479326516389847\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0258)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "306 0.02730574831366539\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4146, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0271)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4146, grad_fn=<SelectBackward>)\n",
      "307 0.02616216242313385\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0259)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "308 0.025088656693696976\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0243)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "309 0.024050477892160416\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0241)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "310 0.023058408871293068\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0234)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "311 0.02210426516830921\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0231)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "312 0.021197544410824776\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0236)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "313 0.02033260278403759\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0248)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "314 0.01949072815477848\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0244)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "315 0.01868683472275734\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0237)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "316 0.01792408712208271\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0245)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "317 0.017189577221870422\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0232)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "318 0.01650119759142399\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0256)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "319 0.015823975205421448\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0215)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "320 0.015181316994130611\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0223)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "321 0.014568387530744076\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0222)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "322 0.013979589566588402\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0232)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "323 0.013408856466412544\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0232)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "324 0.012864040210843086\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0237)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "325 0.012344363145530224\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0232)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "326 0.011851351708173752\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0216)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "327 0.01137469056993723\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0191)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "328 0.010913578793406487\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0205)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "329 0.010477387346327305\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0218)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "330 0.010053048841655254\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0206)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "331 0.009659841656684875\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0213)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "332 0.009274924173951149\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0191)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "333 0.00890426430851221\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0196)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "334 0.008549612946808338\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0193)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "335 0.008208905346691608\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0197)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "336 0.00788700208067894\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0182)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "337 0.007580157835036516\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0193)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "338 0.007276599295437336\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0175)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "339 0.006993078626692295\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0200)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "340 0.006725864019244909\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0192)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341 0.006463074591010809\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0192)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "342 0.006213710643351078\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0183)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "343 0.005975247826427221\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0191)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "344 0.005743937101215124\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0179)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "345 0.005519538652151823\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0175)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "346 0.005308873951435089\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0184)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "347 0.005102177150547504\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0159)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "348 0.004909503273665905\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0170)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "349 0.004726835526525974\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0165)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "350 0.004549104254692793\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0170)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "351 0.004376677796244621\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0181)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "352 0.004215379245579243\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0176)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "353 0.004055490251630545\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0171)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "354 0.0039061359129846096\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0166)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "355 0.003761179046705365\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0161)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "356 0.0036198049783706665\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0153)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "357 0.0034837874118238688\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0151)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "358 0.0033574518747627735\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0148)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "359 0.003231979673728347\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0161)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "360 0.0031124327797442675\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0153)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "361 0.0030040277633816004\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0144)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "362 0.0028966732788830996\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0142)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "363 0.002795763313770294\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0146)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "364 0.0026935653295367956\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0143)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "365 0.0025970120914280415\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0147)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "366 0.0025071725249290466\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0162)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "367 0.0024195429868996143\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0153)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "368 0.0023342168424278498\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0145)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "369 0.002255184343084693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0135)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "370 0.002174831461161375\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0133)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "371 0.0021008409094065428\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0127)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "372 0.0020254747942090034\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0133)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "373 0.001958318753167987\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0139)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "374 0.0018933096434921026\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0134)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "375 0.0018288397695869207\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0131)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "376 0.0017659112345427275\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0138)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "377 0.0017088891472667456\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0137)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "378 0.0016503268852829933\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0132)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "379 0.00159764988347888\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0121)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "380 0.0015465648612007499\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0130)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "381 0.001495366101153195\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0126)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "382 0.001446315087378025\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0124)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "383 0.001401291461661458\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0127)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "384 0.0013563594548031688\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0120)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "385 0.0013115706387907267\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0117)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "386 0.0012696728808805346\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0116)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "387 0.0012298779329285026\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0109)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "388 0.0011920410906895995\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0115)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "389 0.0011573712108656764\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0113)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "390 0.0011218044674023986\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0114)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "391 0.0010859783506020904\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0114)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "392 0.0010549977887421846\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0110)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "393 0.0010218312963843346\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0106)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "394 0.0009924257174134254\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0099)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "395 0.0009630265412852168\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0099)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "396 0.0009338104864582419\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0108)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "397 0.0009083498734980822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0106)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "398 0.0008809894789010286\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0106)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "399 0.0008567065233364701\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0111)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "400 0.0008317919564433396\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0101)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "401 0.0008083650609478354\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0106)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "402 0.0007863552891649306\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0103)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "403 0.0007628189632669091\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0102)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "404 0.0007407345110550523\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0103)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "405 0.0007210075855255127\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0101)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "406 0.0007015084265731275\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0095)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "407 0.000680896861013025\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0103)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "408 0.0006631885771639645\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0101)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "409 0.0006437019328586757\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0102)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "410 0.0006272933096624911\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0099)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "411 0.0006111381226219237\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0099)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "412 0.0005949466140009463\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0095)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "413 0.0005790370050817728\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0086)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "414 0.0005639365408569574\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0082)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "415 0.0005496072117239237\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0083)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "416 0.0005346565740182996\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0083)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "417 0.0005212781252339482\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0085)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "418 0.000508422905113548\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0091)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "419 0.0004959433572366834\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0090)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "420 0.000481600989587605\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0092)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "421 0.0004693706869147718\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0081)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "422 0.00045753619633615017\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0085)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "423 0.0004463503719307482\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0083)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "424 0.00043561853817664087\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0072)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "425 0.00042471816414035857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0069)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "426 0.0004151290631853044\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0074)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "427 0.00040566851384937763\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0078)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "428 0.0003951519320253283\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0073)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "429 0.0003861763107124716\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0081)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "430 0.0003772979835048318\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0079)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "431 0.0003677872591651976\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0083)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "432 0.00035942913382314146\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0089)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "433 0.00035072004538960755\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0090)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "434 0.00034334935480728745\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0084)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "435 0.0003350196056999266\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0086)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "436 0.0003277080541010946\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0090)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "437 0.0003209662390872836\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0091)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "438 0.0003127250529360026\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0076)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "439 0.0003062385367229581\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0081)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "440 0.0002998284180648625\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0091)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "441 0.0002934409712906927\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0083)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "442 0.00028643565019592643\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0093)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "443 0.0002802703238558024\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0086)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "444 0.00027403607964515686\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0079)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "445 0.0002685088838916272\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0075)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "446 0.0002627299400046468\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0074)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "447 0.0002573652018327266\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0080)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "448 0.00025147153064608574\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0073)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "449 0.00024646453675813973\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0069)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "450 0.00024194762227125466\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0075)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "451 0.00023661632440052927\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0074)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "452 0.00023151030472945422\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0072)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "453 0.000226925389142707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0077)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "454 0.00022234868083614856\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0076)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "455 0.00021801391267217696\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0073)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "456 0.00021377555094659328\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0080)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "457 0.00020888303697574884\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0075)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "458 0.00020505860447883606\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0073)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "459 0.00020096561638638377\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0085)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "460 0.00019719880947377533\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0075)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "461 0.00019326219626236707\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0080)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "462 0.00018952459504362196\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0077)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "463 0.00018607988022267818\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0072)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "464 0.00018243944214191288\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0068)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "465 0.00017926766304299235\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0072)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "466 0.00017576233949512243\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0078)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "467 0.00017256128194276243\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0083)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "468 0.00016902436618693173\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0079)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "469 0.0001661540154600516\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0076)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "470 0.00016363391478080302\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0077)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "471 0.00016032610437832773\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0076)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "472 0.00015741812239866704\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0077)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "473 0.00015466725744772702\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0070)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "474 0.00015202676877379417\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0072)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "475 0.0001490314316470176\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0070)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "476 0.0001468570262659341\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0067)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "477 0.00014395378821063787\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0067)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "478 0.00014167990593705326\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0071)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "479 0.00013888451212551445\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0070)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "480 0.00013651348126586527\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0074)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481 0.00013418008165899664\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0074)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "482 0.0001316038251388818\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0073)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "483 0.00012977217556908727\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0071)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "484 0.00012775271898135543\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0070)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "485 0.00012576201697811484\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0073)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "486 0.00012315454659983516\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0070)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "487 0.0001213148352690041\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0070)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "488 0.00011927606828976423\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0070)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "489 0.00011736282613128424\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0077)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "490 0.000115306640509516\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0073)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "491 0.00011361220822436735\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0070)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "492 0.0001114284314098768\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0071)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "493 0.00010988642316078767\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0071)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "494 0.00010800234304042533\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0067)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "495 0.00010632492922013626\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0059)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "496 0.00010502553777769208\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0057)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "497 0.00010332968668080866\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0059)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "498 0.00010160305828321725\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0058)\n",
      "w1.gred after clean  tensor(0.)\n",
      "old w1[0]: tensor(0.6916, grad_fn=<SelectBackward>)\n",
      "old w2[0]: tensor(0.4147, grad_fn=<SelectBackward>)\n",
      "499 0.00010011873382609338\n",
      "new w1[0]: tensor(0.6916, requires_grad=True)\n",
      "new w2[0]: tensor(0.4147, requires_grad=True)\n",
      "w1.gred before clean  tensor(-0.0062)\n",
      "w1.gred after clean  tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "# N是批大小；D_in是输入维度；\n",
    "# H是隐藏层维度；D_out是输出维度  \n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 产生随机输入和输出数据\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "\n",
    "# 产生随机权重tensor，将requires_grad设置为True意味着我们希望在反向传播时候计算这些值的梯度\n",
    "w1 = torch.randn(D_in, H, device=device, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    '''torch.clamp(input, min, max, out=None) → Tensor\n",
    "    \n",
    "          | min, if x_i < min\n",
    "    y_i = | x_i, if min <= x_i <= max\n",
    "          | max, if x_i > max\n",
    "          \n",
    "    '''\n",
    "\n",
    "    print('old w1[0]:',w1[0][0])\n",
    "    print('old w2[0]:',w2[0][0])\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.item())\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "\n",
    "    # 使用梯度下降更新权重。对于这一步，我们只想对w1和w2的值进行原地改变；不想为更新阶段构建计算图，\n",
    "    # 所以我们使用torch.no_grad()上下文管理器防止PyTorch为更新构建计算图\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "        print('new w1[0]:',w1[0][0])\n",
    "        print('new w2[0]:',w2[0][0])\n",
    "        print('w1.gred before clean ',w1.grad[0][0])\n",
    "        # 反向传播之后手动置零梯度\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()\n",
    "        print('w1.gred after clean ',w1.grad[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch 线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "tensor([[2.],\n",
      "        [4.],\n",
      "        [6.]])\n"
     ]
    }
   ],
   "source": [
    "# train data\n",
    "x_data = Variable(torch.Tensor([[1.0], [2.0], [3.0]]))\n",
    "#x_data = torch.randn( 3,1,requires_grad=True)\n",
    "y_data = Variable(torch.Tensor([[2.0], [4.0], [6.0]]))\n",
    "#y_data = torch.randn(3,1,requires_grad=True)\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\torch\\nn\\_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "D:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\loss.py:443: UserWarning: Using a target size (torch.Size([3, 1])) that is different to the input size (torch.Size([3, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 262.8558654785156\n",
      "1 117.80699157714844\n",
      "2 53.223976135253906\n",
      "3 24.462249755859375\n",
      "4 11.647305488586426\n",
      "5 5.931568622589111\n",
      "6 3.3763561248779297\n",
      "7 2.22827410697937\n",
      "8 1.7067582607269287\n",
      "9 1.464321494102478\n",
      "10 1.3462709188461304\n",
      "11 1.283738136291504\n",
      "12 1.246064305305481\n",
      "13 1.2195981740951538\n",
      "14 1.1982605457305908\n",
      "15 1.179343819618225\n",
      "16 1.161639928817749\n",
      "17 1.1446090936660767\n",
      "18 1.1280096769332886\n",
      "19 1.1117318868637085\n",
      "20 1.0957245826721191\n",
      "21 1.0799640417099\n",
      "22 1.0644372701644897\n",
      "23 1.0491373538970947\n",
      "24 1.0340585708618164\n",
      "25 1.019196629524231\n",
      "26 1.0045491456985474\n",
      "27 0.9901120662689209\n",
      "28 0.975882351398468\n",
      "29 0.9618576169013977\n",
      "30 0.9480340480804443\n",
      "31 0.9344094395637512\n",
      "32 0.9209805130958557\n",
      "33 0.9077445864677429\n",
      "34 0.8946987390518188\n",
      "35 0.8818402290344238\n",
      "36 0.869167149066925\n",
      "37 0.8566758036613464\n",
      "38 0.8443641066551208\n",
      "39 0.8322291374206543\n",
      "40 0.8202686309814453\n",
      "41 0.8084799647331238\n",
      "42 0.7968609929084778\n",
      "43 0.7854088544845581\n",
      "44 0.774121105670929\n",
      "45 0.7629959583282471\n",
      "46 0.752030611038208\n",
      "47 0.7412229180335999\n",
      "48 0.7305701375007629\n",
      "49 0.7200708389282227\n",
      "tensor([[1.]])\n",
      "predict (after training) 1 tensor(2.2890)\n"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 3) \n",
    "        '''\n",
    "        class torch.nn.Linear（in_features，out_features，bias = True )\n",
    "        对传入数据应用线性变换：y = A x+ b\n",
    "        '''\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "# our model\n",
    "model = Model()\n",
    "\n",
    "criterion = torch.nn.MSELoss(size_average=False) # Defined loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # Defined optimizer\n",
    "\n",
    "# Training: forward, loss, backward, step\n",
    "# Training loop\n",
    "for epoch in range(50):\n",
    "    # Forward pass\n",
    "    y_pred = model(x_data)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.item())\n",
    "\n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    # perform backward pass\n",
    "    loss.backward()\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "# After training\n",
    "hour_var = Variable(torch.Tensor([[1.0]]))\n",
    "print(hour_var)\n",
    "print(\"predict (after training)\", 1, model.forward(hour_var).data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = ToPILImage() # 可以把Tensor转成Image，方便可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    " #第一次运行程序torchvision会自动下载CIFAR-10数据集，\n",
    "# 大约100M，需花费一定的时间，\n",
    "# 如果已经下载有CIFAR-10，可通过root参数指定\n",
    "\n",
    "# 定义对数据的预处理\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(), # 转为Tensor\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # 归一化\n",
    "                             ])\n",
    "\n",
    "# 训练集\n",
    "trainset = tv.datasets.CIFAR10(\n",
    "                    root='D:/ML_Study/', \n",
    "                    train=True, \n",
    "                    download=False,\n",
    "                    transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "                    trainset, \n",
    "                    batch_size=4,\n",
    "                    shuffle=True, \n",
    "                    num_workers=2)\n",
    "\n",
    "# 测试集\n",
    "testset = tv.datasets.CIFAR10(\n",
    "                    'D:/ML_Study/',\n",
    "                    train=False, \n",
    "                    download=False, \n",
    "                    transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "                    testset,\n",
    "                    batch_size=4, \n",
    "                    shuffle=False,\n",
    "                    num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100 at 0x66E6B70>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data, label) = trainset[100]\n",
    "print(classes[label])\n",
    "\n",
    "# (data + 1) / 2是为了还原被归一化的数据\n",
    "show((data + 1) / 2).resize((100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ship        frog       truck       horse\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=400x100 at 0x6581940>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next() # 返回4张图片及标签\n",
    "print(' '.join('%11s'%classes[labels[j]] for j in range(4)))\n",
    "show(tv.utils.make_grid((images+1)/2)).resize((400,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  \n",
    "        self.fc1   = nn.Linear(16*5*5, 120)  \n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) \n",
    "        x = x.view(x.size()[0], -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import optim\n",
    "criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.220\n",
      "[1,  4000] loss: 1.883\n",
      "[1,  6000] loss: 1.700\n",
      "[1,  8000] loss: 1.603\n",
      "[1, 10000] loss: 1.519\n",
      "[1, 12000] loss: 1.500\n",
      "[2,  2000] loss: 1.422\n",
      "[2,  4000] loss: 1.382\n",
      "[2,  6000] loss: 1.319\n",
      "[2,  8000] loss: 1.330\n",
      "[2, 10000] loss: 1.294\n",
      "[2, 12000] loss: 1.263\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(8)\n",
    "for epoch in range(2):  \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        # 输入数据\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()   \n",
    "        \n",
    "        # 更新参数 \n",
    "        optimizer.step()\n",
    "        \n",
    "        # 打印log信息\n",
    "        # loss 是一个scalar,需要使用loss.item()来获取数值，不能使用loss[0]\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999: # 每2000个batch打印一下训练状态\n",
    "            print('[%d, %5d] loss: %.3f' \\\n",
    "                  % (epoch+1, i+1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实际的label:       cat     ship     ship    plane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=400x100 at 0x6581978>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next() # 一个batch返回4张图片\n",
    "print('实际的label: ', ' '.join(\\\n",
    "            '%08s'%classes[labels[j]] for j in range(4)))\n",
    "show(tv.utils.make_grid(images / 2 - 0.5)).resize((400,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果:    cat  ship  ship  ship\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 计算图片在每个类别上的分数\n",
    "outputs = net(images)\n",
    "# 得分最高的那个类\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print('预测结果: ', ' '.join('%5s'\\\n",
    "            % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000张测试集中的准确率为: 54 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0 # 预测正确的图片数\n",
    "total = 0 # 总共的图片数\n",
    "\n",
    "\n",
    "# 由于测试的时候不需要求导，可以暂时关闭autograd，提高速度，节约内存\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "print('10000张测试集中的准确率为: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
